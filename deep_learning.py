# -*- coding: utf-8 -*-
"""deep learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XEus3V_94iwbbXKrRLy8kLdLdTZNgI4c
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c byu-locating-bacterial-flagellar-motors-v2

!pip install torch torchvision tqdm matplotlib

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision.io import read_image
from torchvision.transforms import v2
import pandas as pd
import os

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

base_dir = '/content/data'
train_csv_path = os.path.join(base_dir, 'train.csv')
train_path = os.path.join(base_dir, 'train')
val_path = os.path.join(base_dir, 'val')

class FlagellarDataset(Dataset):
    def __init__(self, csv_file, img_dir, train=True):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.train = train
        self.transform = v2.Compose([
            v2.RandomHorizontalFlip(),
            v2.RandomVerticalFlip(),
            v2.GaussianBlur(3),
            v2.ColorJitter(brightness=0.5)
        ])

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_name = self.data.iloc[idx, 0]
        img_path = os.path.join(self.img_dir, img_name)
        img = read_image(img_path).float() / 255.0

        if self.train:
            img = self.transform(img)

        x, y, motor_visible = self.data.iloc[idx, 1:].astype(float)
        label = torch.tensor([x, y, motor_visible], dtype=torch.float32)

        return img, label

batch_size = 8
train_dataset = FlagellarDataset(train_csv_path, train_path, train=True)
val_dataset = FlagellarDataset(train_csv_path, val_path, train=False)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(32, 1, kernel_size=2, stride=2),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

autoencoder = Autoencoder().to(device)

class CapsuleLayer(nn.Module):
    def __init__(self, in_channels, out_capsules, out_dim):
        super(CapsuleLayer, self).__init__()
        self.capsules = nn.ModuleList([nn.Conv2d(in_channels, out_dim, kernel_size=3, padding=1) for _ in range(out_capsules)])

    def forward(self, x):
        u = [capsule(x) for capsule in self.capsules]
        u_stack = torch.stack(u, dim=1)
        return torch.sqrt((u_stack ** 2).sum(dim=-1))

class CapsuleNet(nn.Module):
    def __init__(self):
        super(CapsuleNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)
        self.capsule = CapsuleLayer(64, 16, 8)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.capsule(x)
        return x

capsnet = CapsuleNet().to(device)

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(100, 128),
            nn.ReLU(),
            nn.Linear(128, 64*64),
            nn.Tanh()
        )

    def forward(self, x):
        x = self.fc(x).view(-1, 1, 64, 64)
        return x

generator = Generator().to(device)

class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=3, padding=1),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

unet = UNet().to(device)

def train_model(model, loader, optimizer, criterion, epochs=5):
    model.train()
    epoch_losses = []
    epoch_accuracies = []

    for epoch in range(epochs):
        total_loss = 0
        correct = 0
        total = 0

        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, imgs)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

            # Calculate accuracy (mean squared error for reconstruction)
            mse = ((outputs - imgs) ** 2).mean()
            accuracy = 1 - mse.item()  # Accuracy as (1 - MSE)
            correct += accuracy * len(imgs)
            total += len(imgs)

        avg_loss = total_loss / len(loader)
        avg_accuracy = correct / total

        epoch_losses.append(avg_loss)
        epoch_accuracies.append(avg_accuracy)

        print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy * 100:.2f}%")

    return epoch_losses, epoch_accuracies

# Training Autoencoder
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.01)
losses, accuracies = train_model(autoencoder, train_loader, optimizer, nn.MSELoss(), epochs=10)

import matplotlib.pyplot as plt

def visualize(img, prediction):
    plt.figure(figsize=(5, 5))
    plt.imshow(img.squeeze().cpu(), cmap='gray')
    plt.title(f'Predicted: {prediction}')
    plt.show()

# Show a sample prediction
sample_img, label = next(iter(val_loader))
pred = autoencoder(sample_img.to(device))
visualize(sample_img[0], pred[0])

import matplotlib.pyplot as plt

def plot_results(epoch_losses, epoch_accuracies):
    epochs = range(1, len(epoch_losses) + 1)

    # Plot Loss
    plt.figure(figsize=(12, 5))

    # Subplot for Loss
    plt.subplot(1, 2, 1)
    plt.plot(epochs, epoch_losses, '-o', color='blue', label='Training Loss')
    plt.title('Training Loss over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.legend()

    # Subplot for Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, [acc * 100 for acc in epoch_accuracies], '-o', color='green', label='Training Accuracy')
    plt.title('Training Accuracy over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.grid(True)
    plt.legend()

    # Display the plots
    plt.tight_layout()
    plt.show()

# Call the function after training
plot_results(losses, accuracies)

